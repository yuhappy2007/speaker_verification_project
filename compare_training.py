"""
å¯¹æ¯”SupConå’ŒTriplet Lossçš„è®­ç»ƒè¿‡ç¨‹
- åŠ è½½ä¸¤ä¸ªè®­ç»ƒçš„losså†å²
- ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
- åˆ†æè®­ç»ƒç¨³å®šæ€§

ç”¨æ³•:
    python compare_training.py
"""

import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json


def load_loss_history(file_path):
    """åŠ è½½losså†å²"""
    losses = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('#') or line.strip() == '':
                continue
            parts = line.strip().split('\t')
            if len(parts) == 2:
                losses.append(float(parts[1]))
    return losses


def analyze_training_stability(losses, name):
    """åˆ†æè®­ç»ƒç¨³å®šæ€§"""
    losses = np.array(losses)

    analysis = {
        'name': name,
        'mean': np.mean(losses),
        'std': np.std(losses),
        'cv': np.std(losses) / np.mean(losses),  # å˜å¼‚ç³»æ•°(è¶Šå°è¶Šç¨³å®š)
        'min': np.min(losses),
        'max': np.max(losses),
        'final_10_avg': np.mean(losses[-10:]),
        'first_10_avg': np.mean(losses[:10]),
    }

    # è®¡ç®—æ”¹è¿›ç‡
    analysis['improvement'] = (
            (analysis['first_10_avg'] - analysis['final_10_avg']) /
            analysis['first_10_avg'] * 100
    )

    return analysis


def plot_loss_comparison(triplet_losses, supcon_losses, save_path):
    """ç»˜åˆ¶losså¯¹æ¯”å›¾"""
    plt.figure(figsize=(14, 5))

    # å­å›¾1: åŸå§‹lossæ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(triplet_losses, label='Triplet Loss', alpha=0.7, linewidth=1)
    plt.plot(supcon_losses, label='SupCon Loss', alpha=0.7, linewidth=1)
    plt.xlabel('Batch')
    plt.ylabel('Loss')
    plt.title('Training Loss Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # å­å›¾2: å¹³æ»‘åçš„lossæ›²çº¿(ç§»åŠ¨å¹³å‡)
    plt.subplot(1, 2, 2)
    window = 10
    triplet_smooth = np.convolve(
        triplet_losses,
        np.ones(window) / window,
        mode='valid'
    )
    supcon_smooth = np.convolve(
        supcon_losses,
        np.ones(window) / window,
        mode='valid'
    )

    plt.plot(triplet_smooth, label='Triplet Loss (smoothed)', linewidth=2)
    plt.plot(supcon_smooth, label='SupCon Loss (smoothed)', linewidth=2)
    plt.xlabel('Batch')
    plt.ylabel('Loss (Moving Average)')
    plt.title(f'Smoothed Loss (window={window})')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f'ğŸ“Š Plot saved: {save_path}')


def main():
    print('=' * 80)
    print('ğŸ“Š TRAINING COMPARISON: SupCon vs Triplet Loss')
    print('=' * 80)

    # åŠ è½½losså†å²
    triplet_file = Path('checkpoints_fixed_200batch/loss_history.txt')
    supcon_file = Path('checkpoints_supcon_200batch/loss_history_supcon.txt')

    if not triplet_file.exists():
        print(f'âŒ Triplet loss file not found: {triplet_file}')
        print('   Please run train_fixed_50batch.py first')
        return

    if not supcon_file.exists():
        print(f'âŒ SupCon loss file not found: {supcon_file}')
        print('   Please run train_supcon.py first')
        return

    triplet_losses = load_loss_history(triplet_file)
    supcon_losses = load_loss_history(supcon_file)

    print(f'âœ… Loaded Triplet losses: {len(triplet_losses)} batches')
    print(f'âœ… Loaded SupCon losses: {len(supcon_losses)} batches')

    # åˆ†æ
    print('\n' + '=' * 80)
    print('ğŸ“ˆ TRAINING STABILITY ANALYSIS')
    print('=' * 80)

    triplet_analysis = analyze_training_stability(triplet_losses, 'Triplet')
    supcon_analysis = analyze_training_stability(supcon_losses, 'SupCon')

    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print(f'\n{"Metric":<20} {"Triplet Loss":<15} {"SupCon Loss":<15} {"Winner":<10}')
    print('-' * 70)

    metrics = [
        ('Mean Loss', 'mean', 'lower'),
        ('Std Dev', 'std', 'lower'),
        ('CV (stability)', 'cv', 'lower'),
        ('Min Loss', 'min', 'lower'),
        ('Max Loss', 'max', 'lower'),
        ('Final 10 Avg', 'final_10_avg', 'lower'),
        ('Improvement %', 'improvement', 'higher'),
    ]

    wins = {'Triplet': 0, 'SupCon': 0}

    for metric_name, key, better in metrics:
        triplet_val = triplet_analysis[key]
        supcon_val = supcon_analysis[key]

        if better == 'lower':
            winner = 'SupCon âœ…' if supcon_val < triplet_val else 'Triplet âœ…'
            if supcon_val < triplet_val:
                wins['SupCon'] += 1
            else:
                wins['Triplet'] += 1
        else:
            winner = 'SupCon âœ…' if supcon_val > triplet_val else 'Triplet âœ…'
            if supcon_val > triplet_val:
                wins['SupCon'] += 1
            else:
                wins['Triplet'] += 1

        print(f'{metric_name:<20} {triplet_val:<15.4f} {supcon_val:<15.4f} {winner:<10}')

    print('-' * 70)
    print(f'{"TOTAL WINS":<20} {wins["Triplet"]:<15} {wins["SupCon"]:<15}')

    # åˆ¤æ–­å“ªä¸ªæ›´å¥½
    print('\n' + '=' * 80)
    print('ğŸ† CONCLUSION')
    print('=' * 80)

    if wins['SupCon'] > wins['Triplet']:
        print('âœ… SupCon Loss shows BETTER performance:')
        if supcon_analysis['cv'] < triplet_analysis['cv']:
            print('   - More stable training (lower CV)')
        if supcon_analysis['improvement'] > triplet_analysis['improvement']:
            print('   - Better convergence (higher improvement)')
        if supcon_analysis['final_10_avg'] < triplet_analysis['final_10_avg']:
            print('   - Lower final loss')
    elif wins['Triplet'] > wins['SupCon']:
        print('âš ï¸  Triplet Loss shows better performance')
        print('   Consider tuning SupCon temperature parameter')
    else:
        print('ğŸ¤ Both methods show similar performance')

    # ç»˜åˆ¶å¯¹æ¯”å›¾
    print('\n' + '=' * 80)
    print('ğŸ“Š Generating comparison plots...')

    plot_path = Path('checkpoints_supcon_200batch/training_comparison.png')
    plot_loss_comparison(triplet_losses, supcon_losses, plot_path)

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_path = Path('checkpoints_supcon_200batch/comparison_report.txt')
    with open(report_path, 'w') as f:
        f.write('=' * 80 + '\n')
        f.write('TRAINING COMPARISON REPORT\n')
        f.write('SupCon vs Triplet Loss\n')
        f.write('=' * 80 + '\n\n')

        f.write('TRIPLET LOSS:\n')
        for key, val in triplet_analysis.items():
            f.write(f'  {key}: {val}\n')

        f.write('\nSUPCON LOSS:\n')
        for key, val in supcon_analysis.items():
            f.write(f'  {key}: {val}\n')

        f.write(f'\nWINNER: {"SupCon" if wins["SupCon"] > wins["Triplet"] else "Triplet"}\n')
        f.write(f'Score: SupCon {wins["SupCon"]} vs Triplet {wins["Triplet"]}\n')

    print(f'ğŸ“„ Report saved: {report_path}')

    print('\n' + '=' * 80)
    print('âœ… Analysis complete!')
    print('=' * 80)


if __name__ == '__main__':
    main()
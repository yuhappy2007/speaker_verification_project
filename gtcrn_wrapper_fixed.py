# """
# GTCRN è¯­éŸ³å¢å¼ºæ¨¡å‹åŒ…è£…å™¨ï¼ˆå®Œå…¨ä¿®å¤ç‰ˆï¼‰
#
# åŠŸèƒ½ï¼š
# 1. åŠ è½½é¢„è®­ç»ƒçš„ GTCRN æ¨¡å‹
# 2. æä¾›ç»Ÿä¸€çš„å¢å¼ºæ¥å£ï¼ˆè‡ªåŠ¨å¤„ç† STFT/ISTFTï¼‰
# 3. æ”¯æŒæ¢¯åº¦è®¡ç®—ï¼ˆç”¨äºè®­ç»ƒï¼‰
# 4. è‡ªåŠ¨å¤„ç†éŸ³é¢‘æ ¼å¼è½¬æ¢
#
# ä½¿ç”¨æ–¹æ³•ï¼š
#     gtcrn = GTCRNWrapper('gtcrn/checkpoints/model_trained_on_vctk.tar')
#     enhanced = gtcrn.enhance(noisy_audio)  # è¾“å…¥æ—¶åŸŸéŸ³é¢‘ï¼Œè¾“å‡ºæ—¶åŸŸéŸ³é¢‘
#
# é‡è¦ï¼šGTCRN åœ¨é¢‘åŸŸå·¥ä½œï¼ˆSTFTï¼‰ï¼ŒåŒ…è£…å™¨è‡ªåŠ¨å¤„ç†æ—¶é¢‘è½¬æ¢
# """
#
# import torch
# import torch.nn as nn
# import sys
# from pathlib import Path
# import warnings
#
# # æ·»åŠ  GTCRN ç›®å½•åˆ° Python è·¯å¾„
# GTCRN_DIR = Path(__file__).parent / 'gtcrn'
# if str(GTCRN_DIR) not in sys.path:
#     sys.path.insert(0, str(GTCRN_DIR))
#
# # STFT å‚æ•°ï¼ˆä¸ GTCRN è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä» infer.py å¾—çŸ¥ï¼‰
# STFT_N_FFT = 512
# STFT_HOP_LENGTH = 256
# STFT_WIN_LENGTH = 512
#
#
# class GTCRNWrapper(nn.Module):
#     """
#     GTCRN æ¨¡å‹åŒ…è£…å™¨ï¼ˆå®Œå…¨ä¿®å¤ç‰ˆï¼‰
#
#     å…³é”®æ”¹è¿›ï¼š
#     1. âœ… è‡ªåŠ¨å¤„ç† STFT/ISTFT è½¬æ¢
#     2. âœ… æ­£ç¡®åŠ è½½ checkpoint æ ¼å¼ ({'model': state_dict})
#     3. âœ… æ”¯æŒè®­ç»ƒæ¨¡å¼ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
#     4. âœ… æ‰¹é‡å¤„ç†
#
#     GTCRN å·¥ä½œåŸç†ï¼š
#     - è¾“å…¥ï¼šæ—¶åŸŸéŸ³é¢‘ [batch, samples] @ 16kHz
#     - å†…éƒ¨ï¼š
#       * STFT â†’ [batch, freq, time, 2]
#       * GTCRN å¤„ç†é¢‘è°± â†’ [batch, freq, time, 2]
#       * ISTFT â†’ [batch, samples]
#     - è¾“å‡ºï¼šæ—¶åŸŸéŸ³é¢‘ [batch, samples] @ 16kHz
#
#     Args:
#         checkpoint_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
#         device: 'cuda' æˆ– 'cpu'
#         sample_rate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤16000ï¼ŒGTCRN å›ºå®šä½¿ç”¨ï¼‰
#         freeze: æ˜¯å¦å†»ç»“å‚æ•°ï¼ˆé»˜è®¤Falseï¼Œå› ä¸ºæˆ‘ä»¬è¦è®­ç»ƒï¼‰
#     """
#
#     def __init__(self,
#                  checkpoint_path='gtcrn/checkpoints/model_trained_on_vctk.tar',
#                  device='cuda',
#                  sample_rate=16000,
#                  freeze=False):
#         super().__init__()
#
#         self.device = device
#         self.sample_rate = sample_rate
#         self.checkpoint_path = Path(checkpoint_path)
#
#         # STFT å‚æ•°ï¼ˆä¸ GTCRN è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
#         self.n_fft = STFT_N_FFT
#         self.hop_length = STFT_HOP_LENGTH
#         self.win_length = STFT_WIN_LENGTH
#
#         # æ³¨å†Œçª—å‡½æ•°ä¸º bufferï¼ˆä¸æ˜¯å‚æ•°ï¼Œä½†ä¼šéšæ¨¡å‹ç§»åŠ¨åˆ° GPUï¼‰
#         # âœ… ä¿®å¤ï¼šç›´æ¥åœ¨ç›®æ ‡è®¾å¤‡ä¸Šåˆ›å»º
#         window = torch.hann_window(self.win_length, device=device).pow(0.5)
#         self.register_buffer('window', window)
#
#         print(f'ğŸ¤ Initializing GTCRN Wrapper (Fixed Version)...')
#         print(f'   Checkpoint: {self.checkpoint_path}')
#         print(f'   Device: {device}')
#         print(f'   Sample rate: {sample_rate} Hz')
#         print(f'   STFT params: n_fft={self.n_fft}, hop={self.hop_length}')
#         print(f'   Freeze parameters: {freeze}')
#
#         # åŠ è½½ GTCRN æ¨¡å‹
#         self._load_model()
#
#         # è®¾ç½®è®­ç»ƒ/å†»ç»“æ¨¡å¼
#         if freeze:
#             self.model.eval()
#             for param in self.model.parameters():
#                 param.requires_grad = False
#             print(f'   âœ… Model loaded and FROZEN')
#         else:
#             self.model.train()  # è®­ç»ƒæ¨¡å¼
#             for param in self.model.parameters():
#                 param.requires_grad = True
#             print(f'   âœ… Model loaded and TRAINABLE')
#
#     def _load_model(self):
#         """åŠ è½½ GTCRN æ¨¡å‹"""
#         try:
#             # æ­¥éª¤1: å¯¼å…¥ GTCRN ç±»
#             try:
#                 from gtcrn import GTCRN
#                 print(f'   ğŸ“¦ Importing GTCRN from gtcrn.py...')
#             except ImportError as e:
#                 error_msg = (
#                     f"Cannot import GTCRN: {e}\n\n"
#                     f"Please install missing dependencies:\n"
#                     f"  pip install einops --break-system-packages\n\n"
#                     f"Or check if gtcrn.py is in: {GTCRN_DIR}"
#                 )
#                 raise ImportError(error_msg)
#
#             # æ­¥éª¤2: åˆ›å»ºæ¨¡å‹å®ä¾‹
#             self.model = GTCRN().to(self.device)
#             print(f'   âœ… GTCRN model instance created')
#
#             # æ­¥éª¤3: åŠ è½½é¢„è®­ç»ƒæƒé‡
#             if self.checkpoint_path.exists():
#                 print(f'   ğŸ“‚ Loading checkpoint: {self.checkpoint_path.name}')
#                 checkpoint = torch.load(
#                     self.checkpoint_path,
#                     map_location=self.device,
#                     weights_only=False  # æ˜ç¡®è®¾ç½®ä»¥é¿å…è­¦å‘Š
#                 )
#
#                 # æ ¹æ® infer.pyï¼Œcheckpoint æ ¼å¼æ˜¯ {'model': state_dict}
#                 if isinstance(checkpoint, dict) and 'model' in checkpoint:
#                     self.model.load_state_dict(checkpoint['model'])
#                     print(f'   âœ… Loaded state_dict from checkpoint["model"]')
#                 elif isinstance(checkpoint, dict):
#                     # å°è¯•ç›´æ¥ä½œä¸º state_dict
#                     self.model.load_state_dict(checkpoint)
#                     print(f'   âœ… Loaded state_dict directly')
#                 else:
#                     raise ValueError(
#                         f"Unexpected checkpoint format. "
#                         f"Expected dict with 'model' key, got: {type(checkpoint)}"
#                     )
#
#                 # ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
#                 self.model = self.model.to(self.device)
#                 print(f'   âœ… Checkpoint loaded successfully')
#
#             else:
#                 warnings.warn(
#                     f"Checkpoint not found: {self.checkpoint_path}. "
#                     "Using randomly initialized model."
#                 )
#
#         except Exception as e:
#             print(f'   âŒ Error loading GTCRN model: {e}')
#             print(f'\nğŸ’¡ Troubleshooting:')
#             print(f'   1. Install einops: pip install einops --break-system-packages')
#             print(f'   2. Ensure gtcrn.py is in: {GTCRN_DIR}')
#             print(f'   3. Ensure checkpoint exists: {self.checkpoint_path}')
#             raise
#
#     def _do_stft(self, audio):
#         """
#         æ‰§è¡Œ STFT
#
#         Args:
#             audio: [batch, samples] æ—¶åŸŸéŸ³é¢‘
#
#         Returns:
#             spec: [batch, freq, time, 2] GTCRN æœŸæœ›çš„æ ¼å¼ï¼ˆå®éƒ¨+è™šéƒ¨ï¼‰
#         """
#         # audio: [batch, samples]
#         # æ–°ç‰ˆ PyTorch æ¨èä½¿ç”¨ return_complex=True
#         spec_complex = torch.stft(
#             audio,
#             n_fft=self.n_fft,
#             hop_length=self.hop_length,
#             win_length=self.win_length,
#             window=self.window,
#             return_complex=True  # è¿”å›å¤æ•°å¼ é‡ [batch, freq, time]
#         )
#
#         # è½¬æ¢ä¸ºå®æ•°æ ¼å¼ [batch, freq, time, 2]
#         # æœ€åä¸€ç»´ï¼š[å®éƒ¨, è™šéƒ¨]
#         spec = torch.view_as_real(spec_complex)  # [batch, freq, time, 2]
#
#         return spec
#
#     def _do_istft(self, spec):
#         """
#         æ‰§è¡Œ ISTFT
#
#         Args:
#             spec: [batch, freq, time, 2] GTCRN è¾“å‡ºçš„æ ¼å¼ï¼ˆå®éƒ¨+è™šéƒ¨ï¼‰
#
#         Returns:
#             audio: [batch, samples] æ—¶åŸŸéŸ³é¢‘
#         """
#         # è½¬æ¢ä¸ºå¤æ•°æ ¼å¼ [batch, freq, time]
#         spec_complex = torch.view_as_complex(spec.contiguous())
#
#         # ISTFT
#         audio = torch.istft(
#             spec_complex,
#             n_fft=self.n_fft,
#             hop_length=self.hop_length,
#             win_length=self.win_length,
#             window=self.window,
#             return_complex=False  # è¿”å›å®æ•°éŸ³é¢‘
#         )
#
#         return audio
#
#     def enhance(self, noisy_audio, return_numpy=False):
#         """
#         å¢å¼ºéŸ³é¢‘ï¼ˆæ—¶åŸŸè¾“å…¥ â†’ æ—¶åŸŸè¾“å‡ºï¼‰
#
#         Args:
#             noisy_audio: å¸¦å™ªéŸ³é¢‘
#                 - torch.Tensor: [batch, samples] æˆ– [batch, 1, samples]
#                 - numpy.ndarray: [samples] æˆ– [1, samples] æˆ– [batch, samples]
#             return_numpy: æ˜¯å¦è¿”å› numpy æ•°ç»„ï¼ˆé»˜è®¤ Falseï¼‰
#
#         Returns:
#             enhanced: å¢å¼ºåçš„éŸ³é¢‘
#                 - torch.Tensor (å¦‚æœ return_numpy=False)
#                 - numpy.ndarray (å¦‚æœ return_numpy=True)
#         """
#         # è½¬æ¢è¾“å…¥æ ¼å¼
#         if isinstance(noisy_audio, torch.Tensor):
#             audio_tensor = noisy_audio
#         else:
#             # numpy array
#             import numpy as np
#             audio_tensor = torch.from_numpy(noisy_audio).float()
#
#         # ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
#         audio_tensor = audio_tensor.to(self.device)
#
#         # ç¡®ä¿æ˜¯ [batch, samples] æ ¼å¼
#         if audio_tensor.dim() == 1:
#             audio_tensor = audio_tensor.unsqueeze(0)  # [samples] -> [1, samples]
#         elif audio_tensor.dim() == 3:
#             audio_tensor = audio_tensor.squeeze(1)  # [batch, 1, samples] -> [batch, samples]
#
#         # è®°å½•åŸå§‹é•¿åº¦ï¼ˆç”¨äºè£å‰ªï¼‰
#         original_length = audio_tensor.shape[-1]
#
#         # STFT: [batch, samples] â†’ [batch, freq, time, 2]
#         noisy_spec = self._do_stft(audio_tensor)
#
#         # GTCRN å¤„ç†: [batch, freq, time, 2] â†’ [batch, freq, time, 2]
#         enhanced_spec = self.model(noisy_spec)
#
#         # ISTFT: [batch, freq, time, 2] â†’ [batch, samples]
#         enhanced = self._do_istft(enhanced_spec)
#
#         # è£å‰ªåˆ°åŸå§‹é•¿åº¦ï¼ˆSTFT/ISTFT å¯èƒ½æ”¹å˜é•¿åº¦ï¼‰
#         if enhanced.shape[-1] > original_length:
#             enhanced = enhanced[..., :original_length]
#         elif enhanced.shape[-1] < original_length:
#             # å¡«å……é›¶
#             padding = original_length - enhanced.shape[-1]
#             enhanced = torch.nn.functional.pad(enhanced, (0, padding))
#
#         # è¿”å›æ ¼å¼
#         if return_numpy:
#             return enhanced.detach().cpu().numpy()
#         else:
#             return enhanced
#
#     def get_trainable_params(self):
#         """
#         è·å–å¯è®­ç»ƒå‚æ•°åˆ—è¡¨
#         ç”¨äºè®¾ç½®ä¼˜åŒ–å™¨
#
#         Returns:
#             list of parameters with requires_grad=True
#         """
#         return [p for p in self.model.parameters() if p.requires_grad]
#
#     def freeze(self):
#         """å†»ç»“æ‰€æœ‰å‚æ•°"""
#         self.model.eval()
#         for param in self.model.parameters():
#             param.requires_grad = False
#         print('ğŸ”’ GTCRN parameters frozen')
#
#     def unfreeze(self):
#         """è§£å†»æ‰€æœ‰å‚æ•°"""
#         self.model.train()
#         for param in self.model.parameters():
#             param.requires_grad = True
#         print('ğŸ”“ GTCRN parameters unfrozen')
#
#     def forward(self, noisy_audio):
#         """å‰å‘ä¼ æ’­ï¼ˆè°ƒç”¨ enhanceï¼‰"""
#         return self.enhance(noisy_audio)
#
#
# def test_gtcrn_wrapper():
#     """æµ‹è¯• GTCRN åŒ…è£…å™¨"""
#     print('=' * 80)
#     print('ğŸ§ª Testing GTCRN Wrapper (Fixed Version)')
#     print('=' * 80)
#
#     device = 'cuda' if torch.cuda.is_available() else 'cpu'
#
#     # æµ‹è¯•é…ç½®
#     checkpoint_path = 'gtcrn/checkpoints/model_trained_on_vctk.tar'
#
#     # æ£€æŸ¥ checkpoint æ˜¯å¦å­˜åœ¨
#     if not Path(checkpoint_path).exists():
#         print(f'\nâš ï¸  Checkpoint not found: {checkpoint_path}')
#         print(f'   Please download from: https://github.com/Xiaobin-Rong/gtcrn')
#         print(f'   Or adjust the path in the code.')
#         return
#
#     try:
#         # åˆå§‹åŒ–åŒ…è£…å™¨
#         print(f'\n[1/5] Initializing GTCRN...')
#         gtcrn = GTCRNWrapper(
#             checkpoint_path=checkpoint_path,
#             device=device,
#             freeze=False  # ä¸å†»ç»“ï¼Œç”¨äºè®­ç»ƒ
#         )
#
#         # æµ‹è¯•æ•°æ®
#         print(f'\n[2/5] Preparing test data...')
#         batch_size = 2
#         duration = 3  # ç§’
#         sr = 16000
#
#         noisy = torch.randn(batch_size, sr * duration).to(device)
#         print(f'   Noisy audio shape: {noisy.shape}')
#
#         # æµ‹è¯•å¢å¼º
#         print(f'\n[3/5] Testing enhancement...')
#         enhanced = gtcrn.enhance(noisy)
#         print(f'   Enhanced audio shape: {enhanced.shape}')
#         print(f'   Enhanced audio device: {enhanced.device}')
#         print(f'   Enhanced has grad_fn: {enhanced.grad_fn is not None}')
#         print(f'   âœ… Shape matches input!')
#
#         # æµ‹è¯•æ¢¯åº¦æµ
#         print(f'\n[4/5] Testing gradient flow...')
#
#         # æ¨¡æ‹ŸæŸå¤±
#         target = torch.randn_like(enhanced)
#         loss = torch.nn.functional.mse_loss(enhanced, target)
#         print(f'   Loss: {loss.item():.6f}')
#
#         # åå‘ä¼ æ’­
#         loss.backward()
#
#         # æ£€æŸ¥æ¢¯åº¦
#         trainable_params = gtcrn.get_trainable_params()
#         has_grad = sum(1 for p in trainable_params if p.grad is not None)
#         total = len(trainable_params)
#
#         print(f'   Parameters with gradient: {has_grad}/{total}')
#
#         if has_grad > 0:
#             # è®¡ç®—æ¢¯åº¦èŒƒæ•°
#             total_norm = 0
#             for p in trainable_params:
#                 if p.grad is not None:
#                     total_norm += p.grad.norm().item() ** 2
#             total_norm = total_norm ** 0.5
#             print(f'   Total gradient norm: {total_norm:.6f}')
#             print(f'   âœ… Gradient flows correctly!')
#         else:
#             print(f'   âŒ No gradients found!')
#
#         # æµ‹è¯• STFT/ISTFT å¾€è¿”
#         print(f'\n[5/5] Testing STFT/ISTFT round-trip...')
#         test_audio = torch.randn(1, sr).to(device)
#         spec = gtcrn._do_stft(test_audio)
#         reconstructed = gtcrn._do_istft(spec)
#
#         print(f'   Original shape: {test_audio.shape}')
#         print(f'   Spec shape: {spec.shape}  # [batch, freq, time, 2]')
#         print(f'   Reconstructed shape: {reconstructed.shape}')
#
#         # æ£€æŸ¥é‡å»ºè¯¯å·®
#         if reconstructed.shape[-1] != test_audio.shape[-1]:
#             # è£å‰ªåˆ°ç›¸åŒé•¿åº¦
#             min_len = min(reconstructed.shape[-1], test_audio.shape[-1])
#             reconstructed = reconstructed[..., :min_len]
#             test_audio = test_audio[..., :min_len]
#
#         mse = torch.nn.functional.mse_loss(reconstructed, test_audio).item()
#         print(f'   STFT/ISTFT MSE: {mse:.6f}')
#         if mse < 1e-5:
#             print(f'   âœ… Perfect reconstruction!')
#         else:
#             print(f'   â„¹ï¸  Small reconstruction error (normal)')
#
#         print('\n' + '=' * 80)
#         print('âœ… All tests passed!')
#         print('=' * 80)
#
#         print('\nğŸ’¡ Usage example:')
#         print('   gtcrn = GTCRNWrapper("gtcrn/checkpoints/model_trained_on_vctk.tar")')
#         print('   enhanced = gtcrn.enhance(noisy_audio)  # Time domain in/out')
#         print('   loss = loss_fn(enhanced, target)')
#         print('   loss.backward()  # Gradients flow to GTCRN')
#         print('   optimizer.step()  # Update GTCRN parameters')
#
#     except ImportError as e:
#         print(f'\nâŒ Import Error: {e}')
#         print(f'\nğŸ“¦ Please install einops:')
#         print(f'   pip install einops --break-system-packages')
#
#     except Exception as e:
#         print(f'\nâŒ Test failed: {e}')
#         print(f'\nDebugging information:')
#         print(f'   - Checkpoint path: {checkpoint_path}')
#         print(f'   - GTCRN directory: {GTCRN_DIR}')
#         import traceback
#         traceback.print_exc()
#
#
# if __name__ == '__main__':
#     test_gtcrn_wrapper()
"""
GTCRN Wrapper - ä¿®å¤ç‰ˆæœ¬ï¼ˆæ”¯æŒå¤šç§ checkpoint æ ¼å¼ï¼‰

ä¿®å¤ï¼š
1. è‡ªåŠ¨æ£€æµ‹ checkpoint æ ¼å¼
2. æ”¯æŒå®Œæ•´è®­ç»ƒçŠ¶æ€ (model_state_dict)
3. æ”¯æŒçº¯æ¨¡å‹æƒé‡
4. æ”¯æŒåŸå§‹ GTCRN checkpoint (.tar)
"""

import torch
import torch.nn as nn
from pathlib import Path
import sys


class GTCRNWrapper:
    """GTCRN æ¨¡å‹åŒ…è£…å™¨ï¼Œæ”¯æŒå¤šç§ checkpoint æ ¼å¼"""

    def __init__(self, checkpoint_path, device='cuda', freeze=False):
        self.checkpoint_path = Path(checkpoint_path)
        self.device = device
        self.freeze = freeze
        self.sr = 16000
        self.n_fft = 512
        self.hop = 256

        print("ğŸ¤ Initializing GTCRN Wrapper (Fixed Version)...")
        print(f"   Checkpoint: {checkpoint_path}")
        print(f"   Device: {device}")
        print(f"   Sample rate: {self.sr} Hz")
        print(f"   STFT params: n_fft={self.n_fft}, hop={self.hop}")
        print(f"   Freeze parameters: {freeze}")

        self._load_gtcrn()
        self._load_model()

        if freeze:
            self._freeze_params()
            print("   âœ… Model loaded and FROZEN")
        else:
            print("   âœ… Model loaded and TRAINABLE")

    def _load_gtcrn(self):
        """åŠ è½½ GTCRN æ¨¡å‹ç±»"""
        try:
            print("   ğŸ“¦ Importing GTCRN from gtcrn.py...")

            # æ·»åŠ  gtcrn ç›®å½•åˆ°è·¯å¾„
            gtcrn_dir = Path(__file__).parent / 'gtcrn'
            if gtcrn_dir.exists():
                sys.path.insert(0, str(gtcrn_dir))

            # å¯¼å…¥ GTCRN
            from gtcrn import GTCRN

            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.model = GTCRN().to(self.device)
            print("   âœ… GTCRN model instance created")

        except ImportError as e:
            print(f"   âŒ Error importing GTCRN: {e}")
            print("\nğŸ’¡ Troubleshooting:")
            print("   1. Install einops: pip install einops --break-system-packages")
            print("   2. Ensure gtcrn.py is in: " + str(Path(__file__).parent / 'gtcrn'))
            raise

    def _load_model(self):
        """åŠ è½½æ¨¡å‹æƒé‡ï¼Œè‡ªåŠ¨æ£€æµ‹ checkpoint æ ¼å¼"""
        if not self.checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpoint not found: {self.checkpoint_path}")

        print(f"   ğŸ“‚ Loading checkpoint: {self.checkpoint_path.name}")

        try:
            # åŠ è½½ checkpoint
            checkpoint = torch.load(self.checkpoint_path, map_location=self.device)

            # æ£€æµ‹ checkpoint æ ¼å¼
            state_dict = self._extract_state_dict(checkpoint)

            # åŠ è½½æƒé‡
            self.model.load_state_dict(state_dict, strict=True)
            print("   âœ… Checkpoint loaded successfully")

        except Exception as e:
            print(f"   âŒ Error loading GTCRN model: {e}")
            print("\nğŸ’¡ Troubleshooting:")
            print("   1. Install einops: pip install einops --break-system-packages")
            print("   2. Ensure gtcrn.py is in: " + str(Path(__file__).parent / 'gtcrn'))
            print(f"   3. Ensure checkpoint exists: {self.checkpoint_path}")
            raise

    def _extract_state_dict(self, checkpoint):
        """
        ä» checkpoint ä¸­æå– state_dictï¼Œæ”¯æŒå¤šç§æ ¼å¼

        æ”¯æŒçš„æ ¼å¼ï¼š
        1. å®Œæ•´è®­ç»ƒçŠ¶æ€ï¼š{'model_state_dict': ..., 'optimizer_state_dict': ..., ...}
        2. åŸå§‹ GTCRNï¼š{'model': ..., 'optimizer': ..., ...}
        3. çº¯æ¨¡å‹æƒé‡ï¼šç›´æ¥æ˜¯ state_dict
        """
        # æ ¼å¼ 1: æˆ‘ä»¬è®­ç»ƒä¿å­˜çš„æ ¼å¼ (train_gtcrn_standalone_fixed.py)
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            print("   ğŸ“‹ Detected format: PyTorch training checkpoint (model_state_dict)")
            return checkpoint['model_state_dict']

        # æ ¼å¼ 2: åŸå§‹ GTCRN æ ¼å¼
        elif isinstance(checkpoint, dict) and 'model' in checkpoint:
            print("   ğŸ“‹ Detected format: Original GTCRN checkpoint (model)")
            return checkpoint['model']

        # æ ¼å¼ 3: çº¯ state_dict
        elif isinstance(checkpoint, dict) and all(
                not key.startswith('_') for key in checkpoint.keys()
        ):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è®­ç»ƒå…ƒæ•°æ®ï¼ˆepoch, optimizer ç­‰ï¼‰
            metadata_keys = {'epoch', 'optimizer_state_dict', 'val_loss', 'history'}
            if metadata_keys & set(checkpoint.keys()):
                # è¿™æ˜¯è®­ç»ƒ checkpointï¼Œä½†æ²¡æœ‰ model_state_dict
                # ç§»é™¤å…ƒæ•°æ®ï¼Œè¿”å›å‰©ä½™éƒ¨åˆ†ä½œä¸º state_dict
                print("   ğŸ“‹ Detected format: Training checkpoint without model_state_dict key")
                state_dict = {k: v for k, v in checkpoint.items()
                              if k not in metadata_keys}
                return state_dict
            else:
                # çº¯ state_dict
                print("   ğŸ“‹ Detected format: Pure state_dict")
                return checkpoint

        else:
            raise ValueError(
                f"Unknown checkpoint format. Keys: {list(checkpoint.keys())[:10]}"
            )

    def _freeze_params(self):
        """å†»ç»“æ¨¡å‹å‚æ•°"""
        for param in self.model.parameters():
            param.requires_grad = False
        self.model.eval()

    def get_trainable_params(self):
        """è·å–å¯è®­ç»ƒå‚æ•°"""
        return [p for p in self.model.parameters() if p.requires_grad]

    def enhance(self, noisy_audio):
        """
        å¢å¼ºéŸ³é¢‘

        Args:
            noisy_audio: [batch, 1, samples] æˆ– [batch, samples]

        Returns:
            enhanced: [batch, 1, samples]
        """
        # ç¡®ä¿è¾“å…¥æ˜¯ 3D
        if noisy_audio.dim() == 2:
            noisy_audio = noisy_audio.unsqueeze(1)  # [batch, samples] -> [batch, 1, samples]

        # STFT
        noisy_spec = torch.stft(
            noisy_audio.squeeze(1),
            n_fft=self.n_fft,
            hop_length=self.hop,
            win_length=self.n_fft,
            window=torch.hann_window(self.n_fft).to(self.device),
            return_complex=True
        )  # [batch, freq, time]

        # è½¬æ¢ä¸ºå¹…åº¦å’Œç›¸ä½
        noisy_mag = torch.abs(noisy_spec)
        noisy_phase = torch.angle(noisy_spec)

        # æ·»åŠ  channel ç»´åº¦
        noisy_mag = noisy_mag.unsqueeze(1)  # [batch, 1, freq, time]

        # GTCRN å¢å¼º
        with torch.set_grad_enabled(not self.freeze):
            enhanced_mag = self.model(noisy_mag)  # [batch, 1, freq, time]

        # ç§»é™¤ channel ç»´åº¦
        enhanced_mag = enhanced_mag.squeeze(1)  # [batch, freq, time]

        # ä½¿ç”¨åŸå§‹ç›¸ä½é‡æ„
        enhanced_spec = enhanced_mag * torch.exp(1j * noisy_phase)

        # iSTFT
        enhanced_audio = torch.istft(
            enhanced_spec,
            n_fft=self.n_fft,
            hop_length=self.hop,
            win_length=self.n_fft,
            window=torch.hann_window(self.n_fft).to(self.device),
            length=noisy_audio.size(2)
        )  # [batch, samples]

        # æ·»åŠ å› channel ç»´åº¦
        enhanced_audio = enhanced_audio.unsqueeze(1)  # [batch, 1, samples]

        return enhanced_audio


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    print("Testing GTCRNWrapper...")

    # æµ‹è¯•ä¸åŒæ ¼å¼çš„ checkpoint
    test_checkpoints = [
        'gtcrn/checkpoints/model_trained_on_vctk.tar',  # åŸå§‹æ ¼å¼
        'checkpoints/gtcrn/gtcrn_best.pth',  # æˆ‘ä»¬çš„æ ¼å¼
    ]

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    for ckpt_path in test_checkpoints:
        if Path(ckpt_path).exists():
            print(f"\n{'=' * 60}")
            print(f"Testing: {ckpt_path}")
            print('=' * 60)

            try:
                wrapper = GTCRNWrapper(ckpt_path, device=device, freeze=True)

                # æµ‹è¯•å¢å¼º
                dummy_audio = torch.randn(2, 1, 16000).to(device)
                enhanced = wrapper.enhance(dummy_audio)

                print(f"âœ… Success! Input: {dummy_audio.shape}, Output: {enhanced.shape}")

            except Exception as e:
                print(f"âŒ Failed: {e}")
        else:
            print(f"âš ï¸  Checkpoint not found: {ckpt_path}")
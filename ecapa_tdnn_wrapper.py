# # """
# # ECAPA-TDNN Wrapper for Speaker Embedding Extraction
# # ä½¿ç”¨ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹
# # """
# #
# # import torch
# # import torch.nn as nn
# # from pathlib import Path
# #
# #
# # class ECAPATDNNWrapper(nn.Module):
# #     """
# #     ECAPA-TDNN è¯´è¯äººæ¨¡å‹ Wrapper
# #
# #     ä½¿ç”¨ SpeechBrain çš„é¢„è®­ç»ƒæ¨¡å‹æå–è¯´è¯äººåµŒå…¥
# #     """
# #
# #     def __init__(self, model_path='pretrained_models/spkrec-ecapa-voxceleb',
# #                  device='cuda', freeze=True):
# #         """
# #         åˆå§‹åŒ– ECAPA-TDNN
# #
# #         Args:
# #             model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
# #             device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
# #             freeze: æ˜¯å¦å†»ç»“æ¨¡å‹å‚æ•°
# #         """
# #         super().__init__()
# #
# #         self.device = device
# #         self.model_path = Path(model_path)
# #         self.freeze = freeze
# #
# #         print(f"\nğŸ¤ Initializing ECAPA-TDNN Speaker Model...")
# #         print(f"   Model path: {self.model_path}")
# #         print(f"   Device: {self.device}")
# #         print(f"   Freeze: {self.freeze}")
# #
# #         # åŠ è½½æ¨¡å‹
# #         self._load_model()
# #
# #         # å†»ç»“å‚æ•°
# #         if self.freeze:
# #             for param in self.parameters():
# #                 param.requires_grad = False
# #             self.eval()
# #             print(f"   âœ… Model loaded and FROZEN")
# #         else:
# #             print(f"   âœ… Model loaded (trainable)")
# #
# #     def _load_model(self):
# #         """åŠ è½½ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹"""
# #         try:
# #             from speechbrain.inference.speaker import EncoderClassifier
# #
# #             # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
# #             self.classifier = EncoderClassifier.from_hparams(
# #                 source=str(self.model_path),
# #                 run_opts={"device": self.device}
# #             )
# #
# #             print(f"   âœ… SpeechBrain ECAPA-TDNN loaded successfully")
# #
# #         except ImportError:
# #             raise ImportError(
# #                 "SpeechBrain not installed! Please run:\n"
# #                 "pip install speechbrain"
# #             )
# #         except Exception as e:
# #             raise RuntimeError(f"Failed to load ECAPA-TDNN: {e}")
# #
# #     def forward(self, audio):
# #         """
# #         æå–è¯´è¯äººåµŒå…¥
# #
# #         Args:
# #             audio: éŸ³é¢‘å¼ é‡
# #                 - [batch, samples] æˆ–
# #                 - [batch, 1, samples]
# #
# #         Returns:
# #             embeddings: [batch, embedding_dim] (é€šå¸¸æ˜¯ 192)
# #         """
# #         # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
# #         if audio.dim() == 3:
# #             # [batch, 1, samples] -> [batch, samples]
# #             audio = audio.squeeze(1)
# #
# #         batch_size = audio.size(0)
# #
# #         # æå–åµŒå…¥ï¼ˆé€ä¸ªæ ·æœ¬ï¼Œå› ä¸ºSpeechBrainçš„æ‰¹å¤„ç†å¯èƒ½æœ‰é—®é¢˜ï¼‰
# #         embeddings_list = []
# #
# #         for i in range(batch_size):
# #             # è·å–å•ä¸ªéŸ³é¢‘æ ·æœ¬ [samples]
# #             audio_sample = audio[i]
# #
# #             # SpeechBrain encode_batchéœ€è¦ [batch, samples]
# #             audio_batch = audio_sample.unsqueeze(0)  # [1, samples]
# #
# #             # æå–åµŒå…¥
# #             with torch.no_grad() if self.freeze else torch.enable_grad():
# #                 # encode_batchè¿”å›çš„æ˜¯ä¸€ä¸ªå¼ é‡
# #                 embedding = self.classifier.encode_batch(audio_batch)
# #                 # embedding shape: [1, 1, embedding_dim] éœ€è¦squeeze
# #                 embedding = embedding.squeeze()  # [embedding_dim]
# #
# #             embeddings_list.append(embedding)
# #
# #         # å †å æˆæ‰¹æ¬¡
# #         embeddings = torch.stack(embeddings_list)  # [batch, embedding_dim]
# #
# #         # L2 å½’ä¸€åŒ–
# #         embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
# #
# #         return embeddings
# #
# #     def extract_embedding(self, audio):
# #         """
# #         ä¾¿æ·æ–¹æ³•ï¼šæå–å•ä¸ªéŸ³é¢‘çš„åµŒå…¥
# #
# #         Args:
# #             audio: [samples] æˆ– [1, samples]
# #
# #         Returns:
# #             embedding: [embedding_dim]
# #         """
# #         if audio.dim() == 1:
# #             audio = audio.unsqueeze(0)  # [samples] -> [1, samples]
# #
# #         with torch.no_grad():
# #             embedding = self.forward(audio)
# #
# #         return embedding.squeeze(0)  # [embedding_dim]
# #
# #
# # def test_ecapa_wrapper():
# #     """æµ‹è¯• ECAPA-TDNN Wrapper"""
# #     print("\n" + "=" * 60)
# #     print("Testing ECAPA-TDNN Wrapper")
# #     print("=" * 60)
# #
# #     # åˆå§‹åŒ–æ¨¡å‹
# #     model = ECAPATDNNWrapper(
# #         model_path='pretrained_models/spkrec-ecapa-voxceleb',
# #         device='cuda' if torch.cuda.is_available() else 'cpu',
# #         freeze=True
# #     )
# #
# #     # æµ‹è¯•ä¸åŒè¾“å…¥æ ¼å¼
# #     device = 'cuda' if torch.cuda.is_available() else 'cpu'
# #
# #     test_cases = [
# #         ("Single sample", torch.randn(1, 16000).to(device)),
# #         ("Batch [2, samples]", torch.randn(2, 16000).to(device)),
# #         ("Batch [2, 1, samples]", torch.randn(2, 1, 16000).to(device)),
# #     ]
# #
# #     for name, test_input in test_cases:
# #         print(f"\n{name}:")
# #         print(f"  Input shape: {test_input.shape}")
# #
# #         try:
# #             output = model(test_input)
# #             print(f"  Output shape: {output.shape}")
# #             print(f"  Output dtype: {output.dtype}")
# #             print(f"  Output norm: {torch.norm(output, dim=1).mean():.4f} (should be ~1.0)")
# #             print(f"  âœ… Success")
# #         except Exception as e:
# #             print(f"  âŒ Error: {e}")
# #
# #     print("\n" + "=" * 60)
# #
# #
# # if __name__ == '__main__':
# #     test_ecapa_wrapper()
# """
# ECAPA-TDNN Wrapper for Speaker Embedding Extraction
# ä½¿ç”¨ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹
#
# ä¿®å¤ï¼š
# - Windows è·¯å¾„å…¼å®¹æ€§ï¼ˆä½¿ç”¨ as_posix() è½¬æ¢ä¸ºæ­£æ–œæ ï¼‰
# - ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®ä¼ é€’ç»™ HuggingFace
# """
#
# import torch
# import torch.nn as nn
# from pathlib import Path
#
#
# class ECAPATDNNWrapper(nn.Module):
#     """
#     ECAPA-TDNN è¯´è¯äººæ¨¡å‹ Wrapper
#
#     ä½¿ç”¨ SpeechBrain çš„é¢„è®­ç»ƒæ¨¡å‹æå–è¯´è¯äººåµŒå…¥
#     """
#
#     def __init__(self, model_path='pretrained_models/spkrec-ecapa-voxceleb',
#                  device='cuda', freeze=True):
#         """
#         åˆå§‹åŒ– ECAPA-TDNN
#
#         Args:
#             model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
#             device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
#             freeze: æ˜¯å¦å†»ç»“æ¨¡å‹å‚æ•°
#         """
#         super().__init__()
#
#         self.device = device
#         self.freeze = freeze
#
#         # âœ… ä¿®å¤ï¼šä½¿ç”¨ Path å¯¹è±¡ä½†è½¬æ¢ä¸º POSIX æ ¼å¼ï¼ˆæ­£æ–œæ ï¼‰
#         # è¿™æ ·åœ¨ Windows å’Œ Linux ä¸Šéƒ½èƒ½æ­£å¸¸å·¥ä½œ
#         model_path_obj = Path(model_path)
#
#         # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
#         if not model_path_obj.is_absolute():
#             model_path_obj = model_path_obj.resolve()
#
#         # è½¬æ¢ä¸º POSIX æ ¼å¼ï¼ˆä½¿ç”¨æ­£æ–œæ ï¼‰
#         self.model_path_str = model_path_obj.as_posix()
#
#         print(f"\nğŸ¤ Initializing ECAPA-TDNN Speaker Model...")
#         print(f"   Model path: {self.model_path_str}")
#         print(f"   Device: {self.device}")
#         print(f"   Freeze: {self.freeze}")
#
#         # åŠ è½½æ¨¡å‹
#         self._load_model()
#
#         # å†»ç»“å‚æ•°
#         if self.freeze:
#             for param in self.parameters():
#                 param.requires_grad = False
#             self.eval()
#             print(f"   âœ… Model loaded and FROZEN")
#         else:
#             print(f"   âœ… Model loaded (trainable)")
#
#     def _load_model(self):
#         """åŠ è½½ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹"""
#         try:
#             from speechbrain.inference.speaker import EncoderClassifier
#
#             # âœ… ä¿®å¤ï¼šä½¿ç”¨ POSIX æ ¼å¼è·¯å¾„ï¼ˆæ­£æ–œæ ï¼‰
#             # HuggingFace ä¸æ¥å—åæ–œæ è·¯å¾„
#             self.classifier = EncoderClassifier.from_hparams(
#                 source=self.model_path_str,  # ä½¿ç”¨ POSIX æ ¼å¼
#                 run_opts={"device": self.device}
#             )
#
#             print(f"   âœ… SpeechBrain ECAPA-TDNN loaded successfully")
#
#         except ImportError:
#             raise ImportError(
#                 "SpeechBrain not installed! Please run:\n"
#                 "pip install speechbrain"
#             )
#         except Exception as e:
#             print(f"   âŒ Error details: {e}")
#             print(f"   Model path used: {self.model_path_str}")
#             raise RuntimeError(f"Failed to load ECAPA-TDNN: {e}")
#
#     def forward(self, audio):
#         """
#         æå–è¯´è¯äººåµŒå…¥
#
#         Args:
#             audio: éŸ³é¢‘å¼ é‡
#                 - [batch, samples] æˆ–
#                 - [batch, 1, samples]
#
#         Returns:
#             embeddings: [batch, embedding_dim] (é€šå¸¸æ˜¯ 192)
#         """
#         # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
#         if audio.dim() == 3:
#             # [batch, 1, samples] -> [batch, samples]
#             audio = audio.squeeze(1)
#
#         batch_size = audio.size(0)
#
#         # æå–åµŒå…¥ï¼ˆé€ä¸ªæ ·æœ¬ï¼Œå› ä¸ºSpeechBrainçš„æ‰¹å¤„ç†å¯èƒ½æœ‰é—®é¢˜ï¼‰
#         embeddings_list = []
#
#         for i in range(batch_size):
#             # è·å–å•ä¸ªéŸ³é¢‘æ ·æœ¬ [samples]
#             audio_sample = audio[i]
#
#             # SpeechBrain encode_batchéœ€è¦ [batch, samples]
#             audio_batch = audio_sample.unsqueeze(0)  # [1, samples]
#
#             # æå–åµŒå…¥
#             with torch.no_grad() if self.freeze else torch.enable_grad():
#                 # encode_batchè¿”å›çš„æ˜¯ä¸€ä¸ªå¼ é‡
#                 embedding = self.classifier.encode_batch(audio_batch)
#                 # embedding shape: [1, 1, embedding_dim] éœ€è¦squeeze
#                 embedding = embedding.squeeze()  # [embedding_dim]
#
#             embeddings_list.append(embedding)
#
#         # å †å æˆæ‰¹æ¬¡
#         embeddings = torch.stack(embeddings_list)  # [batch, embedding_dim]
#
#         # L2 å½’ä¸€åŒ–
#         embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
#
#         return embeddings
#
#     def extract_embedding(self, audio):
#         """
#         ä¾¿æ·æ–¹æ³•ï¼šæå–å•ä¸ªéŸ³é¢‘çš„åµŒå…¥
#
#         Args:
#             audio: [samples] æˆ– [1, samples]
#
#         Returns:
#             embedding: [embedding_dim]
#         """
#         if audio.dim() == 1:
#             audio = audio.unsqueeze(0)  # [samples] -> [1, samples]
#
#         with torch.no_grad():
#             embedding = self.forward(audio)
#
#         return embedding.squeeze(0)  # [embedding_dim]
#
#
# def test_ecapa_wrapper():
#     """æµ‹è¯• ECAPA-TDNN Wrapper"""
#     print("\n" + "=" * 60)
#     print("Testing ECAPA-TDNN Wrapper")
#     print("=" * 60)
#
#     # åˆå§‹åŒ–æ¨¡å‹
#     model = ECAPATDNNWrapper(
#         model_path='pretrained_models/spkrec-ecapa-voxceleb',
#         device='cuda' if torch.cuda.is_available() else 'cpu',
#         freeze=True
#     )
#
#     # æµ‹è¯•ä¸åŒè¾“å…¥æ ¼å¼
#     device = 'cuda' if torch.cuda.is_available() else 'cpu'
#
#     test_cases = [
#         ("Single sample", torch.randn(1, 16000).to(device)),
#         ("Batch [2, samples]", torch.randn(2, 16000).to(device)),
#         ("Batch [2, 1, samples]", torch.randn(2, 1, 16000).to(device)),
#     ]
#
#     for name, test_input in test_cases:
#         print(f"\n{name}:")
#         print(f"  Input shape: {test_input.shape}")
#
#         try:
#             output = model(test_input)
#             print(f"  Output shape: {output.shape}")
#             print(f"  Output dtype: {output.dtype}")
#             print(f"  Output norm: {torch.norm(output, dim=1).mean():.4f} (should be ~1.0)")
#             print(f"  âœ… Success")
#         except Exception as e:
#             print(f"  âŒ Error: {e}")
#
#     print("\n" + "=" * 60)
#
#
# if __name__ == '__main__':
#     test_ecapa_wrapper()
"""
ECAPA-TDNN Wrapper for Speaker Embedding Extraction
ä½¿ç”¨ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç¦»çº¿åŠ è½½ç‰ˆæœ¬ï¼‰

ä¿®å¤ï¼š
- Windows è·¯å¾„å…¼å®¹æ€§ï¼ˆä½¿ç”¨ as_posix() è½¬æ¢ä¸ºæ­£æ–œæ ï¼‰
- å®Œå…¨ç¦»çº¿åŠ è½½ï¼Œä¸éœ€è¦ç½‘ç»œè¿æ¥
- ç›´æ¥ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ¨¡å‹
"""

import torch
import torch.nn as nn
from pathlib import Path
import os


class ECAPATDNNWrapper(nn.Module):
    """
    ECAPA-TDNN è¯´è¯äººæ¨¡å‹ Wrapper

    ä½¿ç”¨ SpeechBrain çš„é¢„è®­ç»ƒæ¨¡å‹æå–è¯´è¯äººåµŒå…¥
    """

    def __init__(self, model_path='pretrained_models/spkrec-ecapa-voxceleb',
                 device='cuda', freeze=True):
        """
        åˆå§‹åŒ– ECAPA-TDNN

        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
            freeze: æ˜¯å¦å†»ç»“æ¨¡å‹å‚æ•°
        """
        super().__init__()

        self.device = device
        self.freeze = freeze

        # ä½¿ç”¨ Path å¯¹è±¡ä½†è½¬æ¢ä¸º POSIX æ ¼å¼ï¼ˆæ­£æ–œæ ï¼‰
        model_path_obj = Path(model_path)

        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not model_path_obj.is_absolute():
            model_path_obj = model_path_obj.resolve()

        # è½¬æ¢ä¸º POSIX æ ¼å¼ï¼ˆä½¿ç”¨æ­£æ–œæ ï¼‰
        self.model_path_str = model_path_obj.as_posix()
        self.model_path = model_path_obj

        print(f"\nğŸ¤ Initializing ECAPA-TDNN Speaker Model...")
        print(f"   Model path: {self.model_path_str}")
        print(f"   Device: {self.device}")
        print(f"   Freeze: {self.freeze}")

        # åŠ è½½æ¨¡å‹
        self._load_model()

        # å†»ç»“å‚æ•°
        if self.freeze:
            for param in self.parameters():
                param.requires_grad = False
            self.eval()
            print(f"   âœ… Model loaded and FROZEN")
        else:
            print(f"   âœ… Model loaded (trainable)")

    def _load_model(self):
        """åŠ è½½ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå®Œå…¨ç¦»çº¿ï¼‰"""
        try:
            from speechbrain.inference.speaker import EncoderClassifier

            # âœ… å…³é”®ï¼šè®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ç¦»çº¿æ¨¡å¼
            os.environ['HF_HUB_OFFLINE'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '1'

            print(f"   ğŸ”’ Offline mode enabled")

            # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ local_files_onlyï¼ˆæ¨èï¼‰
            try:
                self.classifier = EncoderClassifier.from_hparams(
                    source=self.model_path_str,
                    run_opts={"device": self.device},
                    local_files_only=True  # âœ… å¼ºåˆ¶åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                )
                print(f"   âœ… Loaded with local_files_only=True")

            except Exception as e1:
                print(f"   âš ï¸ Method 1 failed: {e1}")
                print(f"   ğŸ“‚ Trying alternative loading method...")

                # æ–¹æ³•2ï¼šç›´æ¥æŒ‡å®š savedirï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
                try:
                    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    required_files = [
                        'hyperparams.yaml',
                        'embedding_model.ckpt',
                        'classifier.ckpt',
                        'mean_var_norm_emb.ckpt'
                    ]

                    missing_files = []
                    for fname in required_files:
                        fpath = self.model_path / fname
                        if not fpath.exists():
                            missing_files.append(fname)

                    if missing_files:
                        raise FileNotFoundError(
                            f"Missing required files in {self.model_path}: {missing_files}\n"
                            f"Please ensure the model is properly downloaded."
                        )

                    # ä½¿ç”¨ savedir å‚æ•°ï¼ˆå‘Šè¯‰å®ƒæ–‡ä»¶å·²ç»åœ¨è¿™é‡Œäº†ï¼‰
                    self.classifier = EncoderClassifier.from_hparams(
                        source=self.model_path_str,
                        savedir=self.model_path_str,  # âœ… æŒ‡å®šæ–‡ä»¶ä½ç½®
                        run_opts={"device": self.device}
                    )
                    print(f"   âœ… Loaded with savedir parameter")

                except Exception as e2:
                    raise RuntimeError(
                        f"Failed to load ECAPA-TDNN with both methods.\n"
                        f"Method 1 error: {e1}\n"
                        f"Method 2 error: {e2}\n"
                        f"Model path: {self.model_path_str}\n"
                        f"\nTroubleshooting:\n"
                        f"1. Check if all model files exist in {self.model_path}\n"
                        f"2. Verify symlinks are valid (if using symlinks)\n"
                        f"3. Try copying actual files instead of symlinks"
                    )

            print(f"   âœ… SpeechBrain ECAPA-TDNN loaded successfully")

        except ImportError:
            raise ImportError(
                "SpeechBrain not installed! Please run:\n"
                "pip install speechbrain"
            )
        except Exception as e:
            print(f"   âŒ Error details: {e}")
            print(f"   Model path used: {self.model_path_str}")
            raise RuntimeError(f"Failed to load ECAPA-TDNN: {e}")

    def forward(self, audio):
        """
        æå–è¯´è¯äººåµŒå…¥

        Args:
            audio: éŸ³é¢‘å¼ é‡
                - [batch, samples] æˆ–
                - [batch, 1, samples]

        Returns:
            embeddings: [batch, embedding_dim] (é€šå¸¸æ˜¯ 192)
        """
        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if audio.dim() == 3:
            # [batch, 1, samples] -> [batch, samples]
            audio = audio.squeeze(1)

        batch_size = audio.size(0)

        # æå–åµŒå…¥ï¼ˆé€ä¸ªæ ·æœ¬ï¼Œå› ä¸ºSpeechBrainçš„æ‰¹å¤„ç†å¯èƒ½æœ‰é—®é¢˜ï¼‰
        embeddings_list = []

        for i in range(batch_size):
            # è·å–å•ä¸ªéŸ³é¢‘æ ·æœ¬ [samples]
            audio_sample = audio[i]

            # SpeechBrain encode_batchéœ€è¦ [batch, samples]
            audio_batch = audio_sample.unsqueeze(0)  # [1, samples]

            # æå–åµŒå…¥
            with torch.no_grad() if self.freeze else torch.enable_grad():
                # encode_batchè¿”å›çš„æ˜¯ä¸€ä¸ªå¼ é‡
                embedding = self.classifier.encode_batch(audio_batch)
                # embedding shape: [1, 1, embedding_dim] éœ€è¦squeeze
                embedding = embedding.squeeze()  # [embedding_dim]

            embeddings_list.append(embedding)

        # å †å æˆæ‰¹æ¬¡
        embeddings = torch.stack(embeddings_list)  # [batch, embedding_dim]

        # L2 å½’ä¸€åŒ–
        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)

        return embeddings

    def extract_embedding(self, audio):
        """
        ä¾¿æ·æ–¹æ³•ï¼šæå–å•ä¸ªéŸ³é¢‘çš„åµŒå…¥

        Args:
            audio: [samples] æˆ– [1, samples]

        Returns:
            embedding: [embedding_dim]
        """
        if audio.dim() == 1:
            audio = audio.unsqueeze(0)  # [samples] -> [1, samples]

        with torch.no_grad():
            embedding = self.forward(audio)

        return embedding.squeeze(0)  # [embedding_dim]


def test_ecapa_wrapper():
    """æµ‹è¯• ECAPA-TDNN Wrapper"""
    print("\n" + "=" * 60)
    print("Testing ECAPA-TDNN Wrapper")
    print("=" * 60)

    # åˆå§‹åŒ–æ¨¡å‹
    model = ECAPATDNNWrapper(
        model_path='pretrained_models/spkrec-ecapa-voxceleb',
        device='cuda' if torch.cuda.is_available() else 'cpu',
        freeze=True
    )

    # æµ‹è¯•ä¸åŒè¾“å…¥æ ¼å¼
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    test_cases = [
        ("Single sample", torch.randn(1, 16000).to(device)),
        ("Batch [2, samples]", torch.randn(2, 16000).to(device)),
        ("Batch [2, 1, samples]", torch.randn(2, 1, 16000).to(device)),
    ]

    for name, test_input in test_cases:
        print(f"\n{name}:")
        print(f"  Input shape: {test_input.shape}")

        try:
            output = model(test_input)
            print(f"  Output shape: {output.shape}")
            print(f"  Output dtype: {output.dtype}")
            print(f"  Output norm: {torch.norm(output, dim=1).mean():.4f} (should be ~1.0)")
            print(f"  âœ… Success")
        except Exception as e:
            print(f"  âŒ Error: {e}")

    print("\n" + "=" * 60)


if __name__ == '__main__':
    test_ecapa_wrapper()
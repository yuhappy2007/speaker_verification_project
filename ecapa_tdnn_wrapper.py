"""
ECAPA-TDNN Wrapper for Speaker Embedding Extraction
ä½¿ç”¨ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹
"""

import torch
import torch.nn as nn
from pathlib import Path


class ECAPATDNNWrapper(nn.Module):
    """
    ECAPA-TDNN è¯´è¯äººæ¨¡å‹ Wrapper

    ä½¿ç”¨ SpeechBrain çš„é¢„è®­ç»ƒæ¨¡å‹æå–è¯´è¯äººåµŒå…¥
    """

    def __init__(self, model_path='pretrained_models/spkrec-ecapa-voxceleb',
                 device='cuda', freeze=True):
        """
        åˆå§‹åŒ– ECAPA-TDNN

        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
            freeze: æ˜¯å¦å†»ç»“æ¨¡å‹å‚æ•°
        """
        super().__init__()

        self.device = device
        self.model_path = Path(model_path)
        self.freeze = freeze

        print(f"\nğŸ¤ Initializing ECAPA-TDNN Speaker Model...")
        print(f"   Model path: {self.model_path}")
        print(f"   Device: {self.device}")
        print(f"   Freeze: {self.freeze}")

        # åŠ è½½æ¨¡å‹
        self._load_model()

        # å†»ç»“å‚æ•°
        if self.freeze:
            for param in self.parameters():
                param.requires_grad = False
            self.eval()
            print(f"   âœ… Model loaded and FROZEN")
        else:
            print(f"   âœ… Model loaded (trainable)")

    def _load_model(self):
        """åŠ è½½ SpeechBrain é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            from speechbrain.inference.speaker import EncoderClassifier

            # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            self.classifier = EncoderClassifier.from_hparams(
                source=str(self.model_path),
                run_opts={"device": self.device}
            )

            print(f"   âœ… SpeechBrain ECAPA-TDNN loaded successfully")

        except ImportError:
            raise ImportError(
                "SpeechBrain not installed! Please run:\n"
                "pip install speechbrain"
            )
        except Exception as e:
            raise RuntimeError(f"Failed to load ECAPA-TDNN: {e}")

    def forward(self, audio):
        """
        æå–è¯´è¯äººåµŒå…¥

        Args:
            audio: éŸ³é¢‘å¼ é‡
                - [batch, samples] æˆ–
                - [batch, 1, samples]

        Returns:
            embeddings: [batch, embedding_dim] (é€šå¸¸æ˜¯ 192)
        """
        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if audio.dim() == 3:
            # [batch, 1, samples] -> [batch, samples]
            audio = audio.squeeze(1)

        batch_size = audio.size(0)

        # æå–åµŒå…¥ï¼ˆé€ä¸ªæ ·æœ¬ï¼Œå› ä¸ºSpeechBrainçš„æ‰¹å¤„ç†å¯èƒ½æœ‰é—®é¢˜ï¼‰
        embeddings_list = []

        for i in range(batch_size):
            # è·å–å•ä¸ªéŸ³é¢‘æ ·æœ¬ [samples]
            audio_sample = audio[i]

            # SpeechBrain encode_batchéœ€è¦ [batch, samples]
            audio_batch = audio_sample.unsqueeze(0)  # [1, samples]

            # æå–åµŒå…¥
            with torch.no_grad() if self.freeze else torch.enable_grad():
                # encode_batchè¿”å›çš„æ˜¯ä¸€ä¸ªå¼ é‡
                embedding = self.classifier.encode_batch(audio_batch)
                # embedding shape: [1, 1, embedding_dim] éœ€è¦squeeze
                embedding = embedding.squeeze()  # [embedding_dim]

            embeddings_list.append(embedding)

        # å †å æˆæ‰¹æ¬¡
        embeddings = torch.stack(embeddings_list)  # [batch, embedding_dim]

        # L2 å½’ä¸€åŒ–
        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)

        return embeddings

    def extract_embedding(self, audio):
        """
        ä¾¿æ·æ–¹æ³•ï¼šæå–å•ä¸ªéŸ³é¢‘çš„åµŒå…¥

        Args:
            audio: [samples] æˆ– [1, samples]

        Returns:
            embedding: [embedding_dim]
        """
        if audio.dim() == 1:
            audio = audio.unsqueeze(0)  # [samples] -> [1, samples]

        with torch.no_grad():
            embedding = self.forward(audio)

        return embedding.squeeze(0)  # [embedding_dim]


def test_ecapa_wrapper():
    """æµ‹è¯• ECAPA-TDNN Wrapper"""
    print("\n" + "=" * 60)
    print("Testing ECAPA-TDNN Wrapper")
    print("=" * 60)

    # åˆå§‹åŒ–æ¨¡å‹
    model = ECAPATDNNWrapper(
        model_path='pretrained_models/spkrec-ecapa-voxceleb',
        device='cuda' if torch.cuda.is_available() else 'cpu',
        freeze=True
    )

    # æµ‹è¯•ä¸åŒè¾“å…¥æ ¼å¼
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    test_cases = [
        ("Single sample", torch.randn(1, 16000).to(device)),
        ("Batch [2, samples]", torch.randn(2, 16000).to(device)),
        ("Batch [2, 1, samples]", torch.randn(2, 1, 16000).to(device)),
    ]

    for name, test_input in test_cases:
        print(f"\n{name}:")
        print(f"  Input shape: {test_input.shape}")

        try:
            output = model(test_input)
            print(f"  Output shape: {output.shape}")
            print(f"  Output dtype: {output.dtype}")
            print(f"  Output norm: {torch.norm(output, dim=1).mean():.4f} (should be ~1.0)")
            print(f"  âœ… Success")
        except Exception as e:
            print(f"  âŒ Error: {e}")

    print("\n" + "=" * 60)


if __name__ == '__main__':
    test_ecapa_wrapper()
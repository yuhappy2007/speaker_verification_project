"""
ç½®ä¿¡åº¦ç½‘ç»œè®­ç»ƒè„šæœ¬ï¼ˆé›†æˆ GTCRNï¼‰

è®­ç»ƒæµç¨‹ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„ GTCRNï¼ˆå†»ç»“ï¼‰
2. åŠ è½½é¢„è®­ç»ƒçš„è¯´è¯äººæ¨¡å‹ ECAPA-TDNNï¼ˆå†»ç»“ï¼‰
3. è®­ç»ƒç½®ä¿¡åº¦ç½‘ç»œèåˆ noisy å’Œ enhanced åµŒå…¥
4. ä½¿ç”¨ Contrastive Loss ä¼˜åŒ–

SNR é…ç½®ï¼š
- è®­ç»ƒï¼šä» [-5, 0, 5, 10, 15] dB ä¸­éšæœºé€‰æ‹©
- æµ‹è¯•ï¼šåœ¨æ¯ä¸ª SNR ä¸Šåˆ†åˆ«è¯„ä¼°

ç”¨æ³•ï¼š
    python train_confidence_gtcrn.py --voxceleb_dir data/voxceleb1 --musan_dir data/musan
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from pathlib import Path
import sys
import argparse
from tqdm import tqdm
import json
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'scripts'))

from gtcrn_wrapper_fixed import GTCRNWrapper
from contrastive_loss import ContrastiveLoss
from dataset_fixed import VoxCelebMusanDataset
from fixed_snr_dataset import FixedSNRDataset, collate_fn_fixed_length


class ConfidenceNetwork(nn.Module):
    """
    ç½®ä¿¡åº¦ç½‘ç»œï¼šèåˆ noisy å’Œ enhanced åµŒå…¥

    è¾“å…¥ï¼š
        emb_noisy: [batch, embedding_dim] - æ¥è‡ª noisy éŸ³é¢‘
        emb_enhanced: [batch, embedding_dim] - æ¥è‡ª GTCRN å¢å¼ºéŸ³é¢‘

    è¾“å‡ºï¼š
        emb_fused: [batch, embedding_dim] - èåˆåçš„åµŒå…¥
    """

    def __init__(self, embedding_dim=192, hidden_dim=256):
        super().__init__()

        # èåˆç½‘ç»œ
        self.fusion = nn.Sequential(
            nn.Linear(embedding_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, embedding_dim)
        )

        # æ³¨æ„åŠ›æƒé‡ï¼ˆå­¦ä¹ æ¯ä¸ªåµŒå…¥çš„é‡è¦æ€§ï¼‰
        self.attention = nn.Sequential(
            nn.Linear(embedding_dim * 2, 64),
            nn.ReLU(),
            nn.Linear(64, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, emb_noisy, emb_enhanced):
        """
        èåˆä¸¤ä¸ªåµŒå…¥

        Args:
            emb_noisy: [batch, embedding_dim]
            emb_enhanced: [batch, embedding_dim]

        Returns:
            emb_fused: [batch, embedding_dim]
        """
        # æ‹¼æ¥
        concat = torch.cat([emb_noisy, emb_enhanced], dim=1)  # [batch, embedding_dim*2]

        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        weights = self.attention(concat)  # [batch, 2]
        w_noisy = weights[:, 0:1]  # [batch, 1]
        w_enhanced = weights[:, 1:2]  # [batch, 1]

        # åŠ æƒèåˆ
        weighted = w_noisy * emb_noisy + w_enhanced * emb_enhanced

        # é€šè¿‡èåˆç½‘ç»œ
        fused = self.fusion(concat)

        # æ®‹å·®è¿æ¥
        output = weighted + fused

        # L2 å½’ä¸€åŒ–
        output = nn.functional.normalize(output, p=2, dim=1)

        return output


def setup_logger(log_dir):
    """è®¾ç½®æ—¥å¿—"""
    log_dir = Path(log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f'train_confidence_{timestamp}.log'

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )

    return logging.getLogger(__name__)


def train_epoch(gtcrn, speaker_model, confidence_net, dataloader, criterion,
                optimizer, device, epoch):
    """è®­ç»ƒä¸€ä¸ª epoch"""
    # GTCRN å’Œè¯´è¯äººæ¨¡å‹å†»ç»“
    gtcrn.eval()
    speaker_model.eval()

    # ç½®ä¿¡åº¦ç½‘ç»œè®­ç»ƒ
    confidence_net.train()

    total_loss = 0

    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')

    for batch_idx, batch in enumerate(pbar):
        # è·å–æ•°æ®
        noisy = batch['anchor_noisy'].to(device)  # [batch, 1, samples]
        speaker_ids = batch['speaker_id']

        # æ„å»ºæ ‡ç­¾ï¼ˆè¯´è¯äºº ID è½¬æ¢ä¸ºè¿ç»­ç´¢å¼•ï¼‰
        unique_speakers = list(set(speaker_ids))
        speaker_to_idx = {spk: idx for idx, spk in enumerate(unique_speakers)}
        labels = torch.tensor([speaker_to_idx[spk] for spk in speaker_ids]).to(device)

        # GTCRN å¢å¼ºï¼ˆå†»ç»“ï¼‰
        with torch.no_grad():
            enhanced = gtcrn.enhance(noisy)  # [batch, 1, samples]

        # æå–åµŒå…¥ï¼ˆå†»ç»“ï¼‰
        with torch.no_grad():
            emb_noisy = speaker_model(noisy)  # [batch, embedding_dim]
            emb_enhanced = speaker_model(enhanced)  # [batch, embedding_dim]

        # ç½®ä¿¡åº¦ç½‘ç»œèåˆ
        emb_fused = confidence_net(emb_noisy, emb_enhanced)

        # è®¡ç®—æŸå¤±
        loss = criterion(emb_fused, labels)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(confidence_net.parameters(), max_norm=5.0)
        optimizer.step()

        # ç»Ÿè®¡
        total_loss += loss.item()

        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({'loss': f"{loss.item():.4f}"})

    avg_loss = total_loss / len(dataloader)
    return {'loss': avg_loss}


def validate(gtcrn, speaker_model, confidence_net, dataloader, criterion, device):
    """éªŒè¯"""
    gtcrn.eval()
    speaker_model.eval()
    confidence_net.eval()

    total_loss = 0

    with torch.no_grad():
        for batch in tqdm(dataloader, desc='Validation'):
            noisy = batch['anchor_noisy'].to(device)
            speaker_ids = batch['speaker_id']

            # æ„å»ºæ ‡ç­¾
            unique_speakers = list(set(speaker_ids))
            speaker_to_idx = {spk: idx for idx, spk in enumerate(unique_speakers)}
            labels = torch.tensor([speaker_to_idx[spk] for spk in speaker_ids]).to(device)

            # GTCRN å¢å¼º
            enhanced = gtcrn.enhance(noisy)

            # æå–åµŒå…¥
            emb_noisy = speaker_model(noisy)
            emb_enhanced = speaker_model(enhanced)

            # èåˆ
            emb_fused = confidence_net(emb_noisy, emb_enhanced)

            # è®¡ç®—æŸå¤±
            loss = criterion(emb_fused, labels)
            total_loss += loss.item()

    avg_loss = total_loss / len(dataloader)
    return {'loss': avg_loss}


def main(args):
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(args.log_dir)
    logger.info('=' * 80)
    logger.info('Confidence Network Training with GTCRN')
    logger.info('=' * 80)
    logger.info(f'SNR values: {args.snr_values}')
    logger.info(f'Arguments: {vars(args)}')

    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f'Device: {device}')

    # åˆ›å»ºæ•°æ®é›†
    logger.info('\nLoading datasets...')

    # è®­ç»ƒé›†
    base_train_dataset = VoxCelebMusanDataset(
        voxceleb_dir=args.voxceleb_dir,
        musan_dir=args.musan_dir,
        split='train',
        snr_range=(-5, 15),
        return_clean=False  # ä¸éœ€è¦ clean éŸ³é¢‘
    )

    train_dataset = FixedSNRDataset(base_train_dataset, snr_values=args.snr_values)

    # éªŒè¯é›†
    val_dataset = VoxCelebMusanDataset(
        voxceleb_dir=args.voxceleb_dir,
        musan_dir=args.musan_dir,
        split='test',
        test_snr=0,
        test_noise_type='noise',
        return_clean=False
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        collate_fn=lambda batch: collate_fn_fixed_length(batch, target_length=48000)
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True,
        collate_fn=lambda batch: collate_fn_fixed_length(batch, target_length=48000)
    )

    logger.info(f'Train samples: {len(train_dataset)}')
    logger.info(f'Val samples: {len(val_dataset)}')

    # åŠ è½½ GTCRNï¼ˆå†»ç»“ï¼‰
    logger.info('\nLoading GTCRN (frozen)...')
    gtcrn = GTCRNWrapper(
        checkpoint_path=args.gtcrn_checkpoint,
        device=device,
        freeze=True  # å†»ç»“
    )

    # åŠ è½½è¯´è¯äººæ¨¡å‹ï¼ˆå†»ç»“ï¼‰
    logger.info('Loading speaker model (frozen)...')
    # TODO: æ›¿æ¢ä¸ºä½ çš„å®é™…è¯´è¯äººæ¨¡å‹
    # speaker_model = YourSpeakerModel()
    # speaker_model.load_state_dict(torch.load(args.speaker_model_path))
    # speaker_model = speaker_model.to(device)
    # speaker_model.eval()

    # å ä½ç¬¦ï¼ˆä½ éœ€è¦æ›¿æ¢ä¸ºå®é™…æ¨¡å‹ï¼‰
    logger.warning('âš ï¸  Using dummy speaker model! Replace with actual ECAPA-TDNN')

    class DummySpeakerModel(nn.Module):
        def __init__(self, embedding_dim=192):
            super().__init__()
            self.conv = nn.Conv1d(1, 64, 3, padding=1)
            self.pool = nn.AdaptiveAvgPool1d(1)
            self.fc = nn.Linear(64, embedding_dim)

        def forward(self, x):
            # x: [batch, 1, samples]
            x = self.conv(x)
            x = self.pool(x).squeeze(-1)
            x = self.fc(x)
            return nn.functional.normalize(x, p=2, dim=1)

    speaker_model = DummySpeakerModel(embedding_dim=args.embedding_dim).to(device)
    speaker_model.eval()

    # åˆå§‹åŒ–ç½®ä¿¡åº¦ç½‘ç»œ
    logger.info('Initializing confidence network...')
    confidence_net = ConfidenceNetwork(
        embedding_dim=args.embedding_dim,
        hidden_dim=args.hidden_dim
    ).to(device)

    # æŸå¤±å‡½æ•°
    criterion = ContrastiveLoss(temperature=args.temperature)

    # ä¼˜åŒ–å™¨ï¼ˆåªä¼˜åŒ–ç½®ä¿¡åº¦ç½‘ç»œï¼‰
    optimizer = optim.AdamW(
        confidence_net.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )

    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=3, verbose=True
    )

    # è®­ç»ƒå†å²
    history = {
        'train_loss': [],
        'val_loss': []
    }

    best_val_loss = float('inf')
    checkpoint_dir = Path(args.checkpoint_dir)
    checkpoint_dir.mkdir(parents=True, exist_ok=True)

    # è®­ç»ƒå¾ªç¯
    logger.info('\nStarting training...')
    logger.info('=' * 80)

    for epoch in range(1, args.num_epochs + 1):
        logger.info(f'\nEpoch {epoch}/{args.num_epochs}')
        logger.info('-' * 80)

        # è®­ç»ƒ
        train_metrics = train_epoch(
            gtcrn, speaker_model, confidence_net, train_loader,
            criterion, optimizer, device, epoch
        )

        logger.info(f'Train - Loss: {train_metrics["loss"]:.4f}')

        # éªŒè¯
        val_metrics = validate(
            gtcrn, speaker_model, confidence_net, val_loader,
            criterion, device
        )

        logger.info(f'Val   - Loss: {val_metrics["loss"]:.4f}')

        # æ›´æ–°å†å²
        history['train_loss'].append(train_metrics['loss'])
        history['val_loss'].append(val_metrics['loss'])

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step(val_metrics['loss'])

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['loss'] < best_val_loss:
            best_val_loss = val_metrics['loss']
            checkpoint_path = checkpoint_dir / 'confidence_net_best.pth'
            torch.save({
                'epoch': epoch,
                'model_state_dict': confidence_net.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': best_val_loss,
                'history': history
            }, checkpoint_path)
            logger.info(f'âœ… Saved best model: {checkpoint_path}')

        # å®šæœŸä¿å­˜
        if epoch % args.save_interval == 0:
            checkpoint_path = checkpoint_dir / f'confidence_net_epoch{epoch}.pth'
            torch.save({
                'epoch': epoch,
                'model_state_dict': confidence_net.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_metrics['loss'],
                'history': history
            }, checkpoint_path)
            logger.info(f'ğŸ’¾ Saved checkpoint: {checkpoint_path}')

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_checkpoint = checkpoint_dir / 'confidence_net_final.pth'
    torch.save({
        'epoch': args.num_epochs,
        'model_state_dict': confidence_net.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'history': history
    }, final_checkpoint)
    logger.info(f'\nâœ… Training complete! Final model saved: {final_checkpoint}')

    # ä¿å­˜å†å²
    history_file = checkpoint_dir / 'training_history.json'
    with open(history_file, 'w') as f:
        json.dump(history, f, indent=2)
    logger.info(f'ğŸ“Š Training history saved: {history_file}')


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Train Confidence Network with GTCRN')

    # æ•°æ®
    parser.add_argument('--voxceleb_dir', type=str, required=True)
    parser.add_argument('--musan_dir', type=str, required=True)
    parser.add_argument('--snr_values', type=int, nargs='+',
                        default=[-5, 0, 5, 10, 15])

    # æ¨¡å‹
    parser.add_argument('--gtcrn_checkpoint', type=str,
                        default='checkpoints/gtcrn/gtcrn_best.pth')
    parser.add_argument('--speaker_model_path', type=str,
                        default='checkpoints/speaker_model.pth')
    parser.add_argument('--embedding_dim', type=int, default=192)
    parser.add_argument('--hidden_dim', type=int, default=256)

    # æŸå¤±
    parser.add_argument('--temperature', type=float, default=0.07)

    # è®­ç»ƒ
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--num_epochs', type=int, default=30)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--weight_decay', type=float, default=1e-5)
    parser.add_argument('--num_workers', type=int, default=4)

    # è¾“å‡º
    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints/confidence')
    parser.add_argument('--log_dir', type=str, default='logs')
    parser.add_argument('--save_interval', type=int, default=5)

    args = parser.parse_args()
    main(args)